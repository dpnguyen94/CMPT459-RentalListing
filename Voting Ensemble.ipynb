{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Ensemble Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, auc, roc_auc_score, roc_curve, log_loss, plot_roc_curve\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_validate, cross_val_score, cross_val_predict, learning_curve, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, LogisticRegressionCV, SGDClassifier, SGDRegressor, LassoLars, BayesianRidge \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier, VotingRegressor, GradientBoostingClassifier, RandomForestClassifier, GradientBoostingRegressor, RandomForestRegressor\n",
    "import sklearn.gaussian_process as gp\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The latest version of processed training data\n",
    "trainCleaned = \"dataset/two-sigma-connect-rental-listing-inquiries/trainTextExtract.json.zip\"\n",
    "trainData = pd.read_json(trainCleaned, convert_dates=['created'])\n",
    "\n",
    "# Processed test data\n",
    "testDataDir = \"dataset/two-sigma-connect-rental-listing-inquiries/testTextExtract.json.zip\"\n",
    "testData = pd.read_json(testDataDir, convert_dates=['created'])\n",
    "\n",
    "# trainData.head(5)\n",
    "# trainData.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing features for prediction\n",
    "\n",
    "The features listed should be necessary for prediction <br/>\n",
    "- Bathrooms<br/>\n",
    "Reason: Interest levels depends on the number of bathrooms a listing has  \n",
    "- Bedrooms<br/>\n",
    "Reason: Interest levels depends on the number of bedrooms a listing has\n",
    "- Price <br/>\n",
    "Reason: Interest levels depends on the listing price\n",
    "- Year, Month, Day<br/>\n",
    "Reason: if the user is planning to move out to another location within a specific date/time-frame, interest may be higher\n",
    "- Number of Photos<br/>\n",
    "Reason: the number of photos in a listing may correlate well with the interest levels\n",
    "- Description Word Count (desc_word_count)<br/>\n",
    "Reason: descriptions with more words could mean very detailed description which lead to higher interest\n",
    "- Description Average Word Length(desc_avg_word_length)<br/>\n",
    "Reason: large average word length could mean very detailed description which lead to higher interest\n",
    "- Number of features (num_features)<br/>\n",
    "Reason: more features within a listing could lead to more interest\n",
    "- Latitude + Longitude <br/>\n",
    "Reason: interest could be higher on specific area of New York"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = ['bathrooms', 'bedrooms', 'price', 'year', 'month', 'day', 'num_photos', 'desc_word_count', 'desc_avg_word_length', 'num_features', 'latitude', 'longitude']\n",
    "X = trainData[features]\n",
    "testX = testData[features]\n",
    "\n",
    "# display(X.head(5))\n",
    "# display(testData.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding: transform target variable to binary codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "le = LabelEncoder()\n",
    "target = trainData[['interest_level']]\n",
    "y = le.fit_transform(target['interest_level'])\n",
    "# display(y)\n",
    "\n",
    "# Alternative\n",
    "# target = trainData[['interest_level']].astype('category')\n",
    "# y = target['interest_level'].cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Ensemble Classifier\n",
    "### Notes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Model: Initialization, Training, Testing\n",
    "\n",
    "Training: Evaluate model using log loss\n",
    "\n",
    "Testing: Output prediction probabilities for test dataset\n",
    "\n",
    "References:\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html\n",
    "- https://towardsdatascience.com/quick-start-to-gaussian-process-regression-36d838810319\n",
    "- https://scikit-learn.org/stable/tutorial/statistical_inference/model_selection.html\n",
    "- https://scikit-learn.org/stable/modules/ensemble.html#voting-regressor\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "- https://scikit-learn.org/stable/modules/sgd.html\n",
    "- https://scikit-learn.org/stable/modules/linear_model.html#bayesian-regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building and Training the Model with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7739791943540626\n"
     ]
    }
   ],
   "source": [
    "gNB = GaussianNB()\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=5000, multi_class='multinomial')\n",
    "gboost = GradientBoostingClassifier(n_estimators=25)\n",
    "rf = RandomForestClassifier(n_estimators=50)\n",
    "# sgd = SGDClassifier(loss='log', max_iter=5000)\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "# svc = SVC(kernel='rbf', C=0.1, probability=True)\n",
    "\n",
    "model = VotingClassifier(\n",
    "    estimators=[('nb', gNB), ('lr', logreg), ('gb', gboost), ('rf', rf), ('knn', knn)],\n",
    "    voting='soft')\n",
    "\n",
    "model.fit(X, y)\n",
    "print(model.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3075004377972025\n"
     ]
    }
   ],
   "source": [
    "# Regressor Model\n",
    "\n",
    "# kernel = gp.kernels.ConstantKernel(1.0, (1e-1, 1e3)) * gp.kernels.RBF(10.0, (1e-3, 1e3))\n",
    "# gpreg = gp.GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, alpha=0.1, normalize_y=True)\n",
    "linreg = LinearRegression()\n",
    "gbreg = GradientBoostingRegressor(random_state=1, n_estimators=10)\n",
    "rfreg = RandomForestRegressor(random_state=1, n_estimators=23)\n",
    "# sgdreg = SGDRegressor(max_iter=1000, tol=1e-3)\n",
    "llars = LassoLars(alpha=0.01)\n",
    "br = BayesianRidge()\n",
    "\n",
    "# model_reg = VotingRegressor(estimators=[('rf', rfreg), ('gb', gbreg)])\n",
    "# model_reg = VotingRegressor(estimators=[('rf', rfreg), ('gb', gbreg), ('lr', linreg)])\n",
    "model_reg = VotingRegressor(estimators=[('rf', rfreg), ('gb', gbreg), ('br', br), ('ll', llars)])\n",
    "\n",
    "model_reg.fit(X, y)\n",
    "print(model_reg.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores: [0.65967831 0.66701038 0.66879769]\n",
      "Mean accuracy: 0.67 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "# Quick CV run & scoring\n",
    "cv_scores = cross_val_score(model, X, y, cv=3)\n",
    "print(\"Accuracy scores:\", cv_scores)\n",
    "print(\"Mean accuracy: %0.2f (+/- %0.2f)\" % (cv_scores.mean(), cv_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.11      0.19       728\n",
      "           1       0.70      0.97      0.82      5858\n",
      "           2       0.45      0.10      0.17      2143\n",
      "\n",
      "    accuracy                           0.69      8729\n",
      "   macro avg       0.59      0.40      0.39      8729\n",
      "weighted avg       0.63      0.69      0.60      8729\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.12      0.20       729\n",
      "           1       0.70      0.97      0.81      5858\n",
      "           2       0.45      0.10      0.16      2142\n",
      "\n",
      "    accuracy                           0.69      8729\n",
      "   macro avg       0.60      0.40      0.39      8729\n",
      "weighted avg       0.63      0.69      0.60      8729\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.09      0.16       728\n",
      "           1       0.70      0.97      0.81      5858\n",
      "           2       0.44      0.11      0.17      2142\n",
      "\n",
      "    accuracy                           0.69      8728\n",
      "   macro avg       0.59      0.39      0.38      8728\n",
      "weighted avg       0.63      0.69      0.60      8728\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.13      0.22       728\n",
      "           1       0.70      0.97      0.82      5858\n",
      "           2       0.45      0.10      0.17      2142\n",
      "\n",
      "    accuracy                           0.69      8728\n",
      "   macro avg       0.61      0.40      0.40      8728\n",
      "weighted avg       0.64      0.69      0.61      8728\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.09      0.15       728\n",
      "           1       0.70      0.98      0.82      5857\n",
      "           2       0.42      0.09      0.15      2143\n",
      "\n",
      "    accuracy                           0.68      8728\n",
      "   macro avg       0.58      0.38      0.37      8728\n",
      "weighted avg       0.63      0.68      0.60      8728\n",
      "\n",
      "Log-loss: [0.7022305014751249, 0.700406172027969, 0.7078261984898403, 0.7013417752120281, 0.7034011093105906] \n",
      "Mean log-loss: 0.7030411513031106\n",
      "Accuracy scores: [0.6877076411960132, 0.6866765952571887, 0.6851512373968836, 0.6889321723189734, 0.6849220898258478] \n",
      "Mean accuracy: 0.6866779471989815\n"
     ]
    }
   ],
   "source": [
    "# Expanded CV runs & scoring\n",
    "cv_LL = []\n",
    "accuracy_scores = []\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "for train_index, val_index in kf.split(X, y):\n",
    "    X_train, X_val = X.iloc[train_index,:], X.iloc[val_index,:]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_prob = model.predict_proba(X_val)\n",
    "    y_pred = model.predict(X_val)\n",
    "    cv_LL.append(log_loss(y_val, y_pred_prob))\n",
    "    accuracy_scores.append(model.score(X_val, y_val))\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    \n",
    "print(\"Log-loss:\", cv_LL, \"\\nMean log-loss:\", np.mean(cv_LL))\n",
    "print(\"Accuracy scores:\", accuracy_scores, \"\\nMean accuracy:\", np.mean(accuracy_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>medium</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listing_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6811958</th>\n",
       "      <td>0.160195</td>\n",
       "      <td>0.541655</td>\n",
       "      <td>0.298150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811960</th>\n",
       "      <td>0.020794</td>\n",
       "      <td>0.791992</td>\n",
       "      <td>0.187214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811964</th>\n",
       "      <td>0.079446</td>\n",
       "      <td>0.636419</td>\n",
       "      <td>0.284135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811971</th>\n",
       "      <td>0.042210</td>\n",
       "      <td>0.693692</td>\n",
       "      <td>0.264098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811974</th>\n",
       "      <td>0.158831</td>\n",
       "      <td>0.435243</td>\n",
       "      <td>0.405927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7748251</th>\n",
       "      <td>0.020559</td>\n",
       "      <td>0.797287</td>\n",
       "      <td>0.182154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7748271</th>\n",
       "      <td>0.086231</td>\n",
       "      <td>0.548133</td>\n",
       "      <td>0.365635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7748273</th>\n",
       "      <td>0.363174</td>\n",
       "      <td>0.369648</td>\n",
       "      <td>0.267179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7754429</th>\n",
       "      <td>0.115872</td>\n",
       "      <td>0.484950</td>\n",
       "      <td>0.399177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7761779</th>\n",
       "      <td>0.015379</td>\n",
       "      <td>0.856389</td>\n",
       "      <td>0.128233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74659 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                high       low    medium\n",
       "listing_id                              \n",
       "6811958     0.160195  0.541655  0.298150\n",
       "6811960     0.020794  0.791992  0.187214\n",
       "6811964     0.079446  0.636419  0.284135\n",
       "6811971     0.042210  0.693692  0.264098\n",
       "6811974     0.158831  0.435243  0.405927\n",
       "...              ...       ...       ...\n",
       "7748251     0.020559  0.797287  0.182154\n",
       "7748271     0.086231  0.548133  0.365635\n",
       "7748273     0.363174  0.369648  0.267179\n",
       "7754429     0.115872  0.484950  0.399177\n",
       "7761779     0.015379  0.856389  0.128233\n",
       "\n",
       "[74659 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the prediction probabilities based on the trained model\n",
    "\n",
    "predictions = model.predict_proba(testX)\n",
    "pred_df = pd.DataFrame(predictions)\n",
    "pred_df.columns = le.classes_\n",
    "pred_df[\"listing_id\"] = testData.listing_id.values\n",
    "pred_df.set_index('listing_id', inplace=True)\n",
    "pred_df.sort_index(inplace=True)\n",
    "\n",
    "display(pred_df)\n",
    "pred_df.to_csv(\"voting_original.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Model: Evaluation (Accuracy & Overfitting Dectection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curve\n",
    "References:\n",
    "- https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html#plot-roc-curves-for-the-multilabel-problem\n",
    "- https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "VotingClassifier should be a binary classifer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-8d41296a0f9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     viz = plot_roc_curve(model, X_test, y_test,\n\u001b[0;32m     16\u001b[0m                          \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ROC fold {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                          alpha=0.3, lw=1, ax=ax)\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0minterp_tpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterp_tpr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_fpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mviz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mviz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0minterp_tpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_plot\\roc_curve.py\u001b[0m in \u001b[0;36mplot_roc_curve\u001b[1;34m(estimator, X, y, sample_weight, drop_intermediate, response_method, name, ax, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: VotingClassifier should be a binary classifer"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Binarize the output\n",
    "y = label_binarize(y, classes=[0, 1, 2])\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "# Add noisy features to make the problem harder\n",
    "random_state = np.random.RandomState(0)\n",
    "n_samples, n_features = X.shape\n",
    "X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]\n",
    "\n",
    "# shuffle and split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# Learn to predict each class against the other\n",
    "classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True,\n",
    "                                 random_state=random_state))\n",
    "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    " \n",
    "#---\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_errors = [] # Log training errors for each model\n",
    "# test_errors = [] # Log testing errors for each model\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# for x in max_depth_list:\n",
    "#     model = tree.DecisionTreeClassifier(max_depth=x) \n",
    "#     model.fit(X_train,y_train)\n",
    "#     train_errors.append(model.score(X_train, y_train))\n",
    "#     test_errors.append(model.score(X_test, y_test))\n",
    "\n",
    "# x = np.arange(len(max_depth_list)) + 1 # Create domain for plot\n",
    "# plt.figure(figsize=(20,10))\n",
    "# plt.xticks(x)\n",
    "# plt.plot(x, train_errors, label='Training Accuracy') # Plot training error over domain\n",
    "# plt.plot(x, test_errors, label='Testing Accuracy') # Plot testing error over domain\n",
    "# plt.xlabel('Maximum Tree Depth') # Label x-axis\n",
    "# plt.ylabel('Model Accuracy') # Label y-axis\n",
    "# plt.legend() # Show plot labels as legend\n",
    "# plt.plot() # Show graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References: \n",
    "- https://scikit-learn.org/stable/modules/model_evaluation.html#accuracy-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvements: parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7362861463727601\n"
     ]
    }
   ],
   "source": [
    "gNB = GaussianNB()\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=5000, multi_class='multinomial', C=0.8)\n",
    "gboost = GradientBoostingClassifier(n_estimators=50)\n",
    "rf = RandomForestClassifier(n_estimators=70, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2)\n",
    "# sgd = SGDClassifier(loss='log', max_iter=5000)\n",
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "# svc = SVC(kernel='rbf', C=0.1, probability=True)\n",
    "\n",
    "model_2 = VotingClassifier(\n",
    "    estimators=[('nb', gNB), ('lr', logreg), ('gb', gboost), ('rf', rf), ('knn', knn)],\n",
    "    voting='soft',\n",
    "    weights=[1,3,2,4,2])\n",
    "\n",
    "# model_2 = make_pipeline(\n",
    "#     PCA(5),\n",
    "#     vcl\n",
    "# )\n",
    "\n",
    "model_2.fit(X, y)\n",
    "print(model_2.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.12      0.20       728\n",
      "           1       0.71      0.97      0.82      5858\n",
      "           2       0.43      0.12      0.19      2143\n",
      "\n",
      "    accuracy                           0.69      8729\n",
      "   macro avg       0.61      0.40      0.40      8729\n",
      "weighted avg       0.64      0.69      0.61      8729\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.12      0.21       729\n",
      "           1       0.71      0.98      0.82      5858\n",
      "           2       0.49      0.12      0.19      2142\n",
      "\n",
      "    accuracy                           0.69      8729\n",
      "   macro avg       0.61      0.41      0.41      8729\n",
      "weighted avg       0.65      0.69      0.61      8729\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.14      0.22       728\n",
      "           1       0.71      0.97      0.82      5858\n",
      "           2       0.47      0.12      0.20      2142\n",
      "\n",
      "    accuracy                           0.69      8728\n",
      "   macro avg       0.61      0.41      0.41      8728\n",
      "weighted avg       0.65      0.69      0.62      8728\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.14      0.23       728\n",
      "           1       0.71      0.97      0.82      5858\n",
      "           2       0.46      0.12      0.19      2142\n",
      "\n",
      "    accuracy                           0.69      8728\n",
      "   macro avg       0.60      0.41      0.41      8728\n",
      "weighted avg       0.64      0.69      0.62      8728\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.14      0.24       728\n",
      "           1       0.71      0.97      0.82      5857\n",
      "           2       0.46      0.13      0.20      2143\n",
      "\n",
      "    accuracy                           0.69      8728\n",
      "   macro avg       0.61      0.41      0.42      8728\n",
      "weighted avg       0.64      0.69      0.62      8728\n",
      "\n",
      "Log-loss: [0.6860624586841036, 0.6784732151484401, 0.6879275863496253, 0.6766659851342309, 0.6822206501401977] \n",
      "Mean log-loss: 0.6822699790913195\n",
      "Accuracy scores: [0.6906862183526177, 0.693893916828961, 0.6932859761686526, 0.6937442713107241, 0.6931714023831348] \n",
      "Mean accuracy: 0.692956357008818\n"
     ]
    }
   ],
   "source": [
    "cv_LL = []\n",
    "accuracy_scores = []\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "for train_index, val_index in kf.split(X, y):\n",
    "    X_train, X_val = X.iloc[train_index,:], X.iloc[val_index,:]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    model_2.fit(X_train, y_train)\n",
    "    y_pred_prob = model_2.predict_proba(X_val)\n",
    "    y_pred = model_2.predict(X_val)\n",
    "    cv_LL.append(log_loss(y_val, y_pred_prob))\n",
    "    accuracy_scores.append(model_2.score(X_val, y_val))\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    \n",
    "print(\"Log-loss:\", cv_LL, \"\\nMean log-loss:\", np.mean(cv_LL))\n",
    "print(\"Accuracy scores:\", accuracy_scores, \"\\nMean accuracy:\", np.mean(accuracy_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>medium</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listing_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6811958</th>\n",
       "      <td>0.083128</td>\n",
       "      <td>0.538321</td>\n",
       "      <td>0.378551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811960</th>\n",
       "      <td>0.026869</td>\n",
       "      <td>0.847864</td>\n",
       "      <td>0.125267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811964</th>\n",
       "      <td>0.086759</td>\n",
       "      <td>0.644379</td>\n",
       "      <td>0.268862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811971</th>\n",
       "      <td>0.031364</td>\n",
       "      <td>0.723381</td>\n",
       "      <td>0.245254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811974</th>\n",
       "      <td>0.167145</td>\n",
       "      <td>0.411796</td>\n",
       "      <td>0.421059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7748251</th>\n",
       "      <td>0.026799</td>\n",
       "      <td>0.707835</td>\n",
       "      <td>0.265366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7748271</th>\n",
       "      <td>0.097838</td>\n",
       "      <td>0.568044</td>\n",
       "      <td>0.334118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7748273</th>\n",
       "      <td>0.240259</td>\n",
       "      <td>0.464553</td>\n",
       "      <td>0.295188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7754429</th>\n",
       "      <td>0.119077</td>\n",
       "      <td>0.484116</td>\n",
       "      <td>0.396807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7761779</th>\n",
       "      <td>0.017606</td>\n",
       "      <td>0.840294</td>\n",
       "      <td>0.142100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74659 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                high       low    medium\n",
       "listing_id                              \n",
       "6811958     0.083128  0.538321  0.378551\n",
       "6811960     0.026869  0.847864  0.125267\n",
       "6811964     0.086759  0.644379  0.268862\n",
       "6811971     0.031364  0.723381  0.245254\n",
       "6811974     0.167145  0.411796  0.421059\n",
       "...              ...       ...       ...\n",
       "7748251     0.026799  0.707835  0.265366\n",
       "7748271     0.097838  0.568044  0.334118\n",
       "7748273     0.240259  0.464553  0.295188\n",
       "7754429     0.119077  0.484116  0.396807\n",
       "7761779     0.017606  0.840294  0.142100\n",
       "\n",
       "[74659 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the prediction probabilities based on the trained model\n",
    "\n",
    "predictions = model_2.predict_proba(testX)\n",
    "pred_df = pd.DataFrame(predictions)\n",
    "pred_df.columns = le.classes_\n",
    "pred_df[\"listing_id\"] = testData.listing_id.values\n",
    "pred_df.set_index('listing_id', inplace=True)\n",
    "pred_df.sort_index(inplace=True)\n",
    "\n",
    "display(pred_df)\n",
    "pred_df.to_csv(\"voting_improved.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
